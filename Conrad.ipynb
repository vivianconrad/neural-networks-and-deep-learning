{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conrad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivianconrad/neural-networks-and-deep-learning/blob/main/Conrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkVG8TVavvLl"
      },
      "source": [
        "## Q1: Build a simple neural network\n",
        "\n",
        "The neural networks contains:\n",
        "- 6 inputs, 2 hidden layer with 6 nodes\n",
        "\n",
        "The neural network performs prediction to obtain:\n",
        "- 6 output values by multiplying inputs with weights.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "- Input layer weight values:\n",
        "\n",
        "            [0.1, 0.2, 0.9, -0.1, 0.2, 0.1],\n",
        "            [-0.1, 0.1, 0.78, 0.2, 0.1, 0.9], \n",
        "            [-0.1, 0.2, 0.1, 0.1, 0.12, 0.9], \n",
        "            [0.1, 0.4, 0.2, 0.1, 0.89, 0.1],\n",
        "            [-0.1, 0.1, 0.12, 0.2, 0.1, 0.9], \n",
        "            [0.1, 0.4, 0.2, 0.1, 0.89, 0.1]\n",
        "\n",
        "- Hidden layer 1 weight values: \n",
        "\n",
        "            [0.3, 0.1, 0.2, 0.1, 0.89, -0.3],\n",
        "            [0.1, -0.2, 0.2, 0.1, 0.34, 0.0],\n",
        "            [0.1, 0.2, 0.7, 0.2, 0.1, 0.0],\n",
        "            [0.1, -0.2, 0.34, 0.2, 0.1, 0.0],\n",
        "            [0.1, 0.2, 0.2, 0.1, 0.7, 0.1],\n",
        "            [0.0, -1.3, -0.6, 0.2, 0.1, 0.1]\n",
        "\n",
        "- Hidden layer 2 weight values: \n",
        "\n",
        "            [0.1, 0.1, 0.79,0.2, 0.1, -0.2],\n",
        "            [0.1, -0.22, 0.47, 0.2, 0.1, 0.2],\n",
        "            [0.3, 0.12, 0.5, 0.2, 0.1, 0.0],\n",
        "            [0.1, -0.2, 0.34, 0.2, 0.1, 0.0],\n",
        "            [0.2, 0.2, 0.2, 0.1, 0.7, 0.1],\n",
        "            [0.1, -1.3, -0.6, 0.1, 0.2, 0.1]\n",
        "\n",
        "- Input Values:\n",
        "\n",
        "  input1 = [88.50]\n",
        "  \n",
        "  input2 = [72.95]\n",
        "  \n",
        "  input3 = [18.25]\n",
        "  \n",
        "  input4 = [0.29]\n",
        "  \n",
        "  input5 = [12.69]\n",
        "  \n",
        "  input6 = [38.2]\n",
        "\n",
        "\n",
        "**Expected Outcome**\n",
        "- [ 37.629953   18.0629716  34.3317195  20.637146   70.034887  -16.620856 ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OFyIl3bZFtg",
        "outputId": "bbaefa0e-1992-4689-9e0a-55986eea9652"
      },
      "source": [
        "# write your code here\n",
        "import numpy as np\n",
        "\n",
        "input_weights = np.array([ \n",
        "            [0.1, 0.2, 0.9, -0.1, 0.2, 0.1],\n",
        "            [-0.1, 0.1, 0.78, 0.2, 0.1, 0.9], \n",
        "            [-0.1, 0.2, 0.1, 0.1, 0.12, 0.9], \n",
        "            [0.1, 0.4, 0.2, 0.1, 0.89, 0.1],\n",
        "            [-0.1, 0.1, 0.12, 0.2, 0.1, 0.9], \n",
        "            [0.1, 0.4, 0.2, 0.1, 0.89, 0.1]])\n",
        "\n",
        "hidden_weights_1 = np.array([  \n",
        "            [0.3, 0.1, 0.2, 0.1, 0.89, -0.3],\n",
        "            [0.1, -0.2, 0.2, 0.1, 0.34, 0.0],\n",
        "            [0.1, 0.2, 0.7, 0.2, 0.1, 0.0],\n",
        "            [0.1, -0.2, 0.34, 0.2, 0.1, 0.0],\n",
        "            [0.1, 0.2, 0.2, 0.1, 0.7, 0.1],\n",
        "            [0.0, -1.3, -0.6, 0.2, 0.1, 0.1]])\n",
        "\n",
        "hidden_weights_2 = np.array([  \n",
        "            [0.1, 0.1, 0.79,0.2, 0.1, -0.2],\n",
        "            [0.1, -0.22, 0.47, 0.2, 0.1, 0.2],\n",
        "            [0.3, 0.12, 0.5, 0.2, 0.1, 0.0],\n",
        "            [0.1, -0.2, 0.34, 0.2, 0.1, 0.0],\n",
        "            [0.2, 0.2, 0.2, 0.1, 0.7, 0.1],\n",
        "            [0.1, -1.3, -0.6, 0.1, 0.2, 0.1]])\n",
        "\n",
        "\n",
        "weights = [input_weights, hidden_weights_1, hidden_weights_2]\n",
        "\n",
        "def simple_neural_network(input, weights):\n",
        "    hidden_layer_1 = input.dot(weights[0])\n",
        "    hidden_layer_2 = hidden_layer_1.dot(weights[1])\n",
        "    prediction_layer = hidden_layer_2.dot(weights[2])\n",
        "    return prediction_layer\n",
        "\n",
        "    \n",
        "input1 = np.array([88.50])\n",
        "input2 = np.array([72.95])\n",
        "input3 = np.array([18.25])\n",
        "input4 = np.array([0.29])\n",
        "input5 = np.array([12.69])\n",
        "input6 = np.array([38.2])\n",
        "\n",
        "input = np.array([input1[0],input2[0],input3[0],input4[0], input5[0], input6[0]])\n",
        "output_prediction = simple_neural_network(input,weights)\n",
        "\n",
        "print(output_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 37.629953   18.0629716  34.3317195  20.637146   70.034887  -16.620856 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx1jtKdZ38jS"
      },
      "source": [
        "## Q2: Write Python code using NumPy that does the following. \n",
        "\n",
        "- Create a function called **create_duplicate_array_of_zeros** which accepts **input_array** as a parameter, where input_array is a NumPy array and we will return a NumPy array made up of zeros with the same dimensions.\n",
        "- The output should be data structure format similar to test cases mentioned below\n",
        "- NumPy is the only library which can be imported. Inbuilt functions which require no import and Datatype methods can be used to solve this problem but No arbitray functions or library can be used.\n",
        "- You can use NumPy zeros() method to for the solution to solve this problem.\n",
        "\n",
        "**Input Array**\n",
        "\n",
        "[[1 2]\n",
        "[3 4]\n",
        "[5 6]] \n",
        "\n",
        "**Expected Outcome** \n",
        "\n",
        "[[0. 0.]\n",
        " [0. 0.]\n",
        " [0. 0.]]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cGk9lM4ZEsB",
        "outputId": "774e1e0a-24f1-41b4-9dc0-1c8310f62e98"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_duplicate_array_of_ones(input_array):\n",
        "  if input_array is not None and type(input_array[0]) is np.ndarray:\n",
        "    output = list()\n",
        "    for arr in input_array:\n",
        "      output.append(np.zeros(len(arr)))\n",
        "    return np.array(output)\n",
        "  return np.zeros(len(input_array))\n",
        "\n",
        "\n",
        "input_array_tuple_list = [np.array([[1, 2], [3, 4]]), np.array([5, 6])]\n",
        "for input_array in input_array_tuple_list:\n",
        "    output_array = create_duplicate_array_of_ones(input_array=input_array)\n",
        "    print(\"Input Array: \\n{0} \\nDuplicated Arrays in Ones: \\n{1}\\n\\n\".format(input_array, output_array))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Array: \n",
            "[[1 2]\n",
            " [3 4]] \n",
            "Duplicated Arrays in Ones: \n",
            "[[0. 0.]\n",
            " [0. 0.]]\n",
            "\n",
            "\n",
            "Input Array: \n",
            "[5 6] \n",
            "Duplicated Arrays in Ones: \n",
            "[0. 0.]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlW3pjLVMLLA"
      },
      "source": [
        "## Q3: Build a k-fold validation neural network using Keras\n",
        "\n",
        "- Use the dataset: data_01.csv\n",
        "- Split the columns into 60 input variables (input_x) and 1 output variable (output_y)\n",
        "- The output variable has string values; hence convert them into integer values 0 and 1.\n",
        "- You can select the number of hidden layers, activation functions, optimizer, batch size, and epochs of your choice.\n",
        "- Neural network paramaters: loss=binary_crossentropy, metrics=accuracy, n_splits=10.\n",
        "\n",
        "**Expected Output**\n",
        "- Mean accuracy: Greater than 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Ul4o0koNKmFx",
        "outputId": "c964171e-7339-433e-cb37-62f1e8c486f1"
      },
      "source": [
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "data = read_csv(\"data_01.csv\", header=None)\n",
        "dataset = data.values\n",
        "\n",
        "input_x = dataset[:,0:60].astype(int)\n",
        "output_y = dataset[:,59].astype(int)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "cross_validationores_scores = []\n",
        "\n",
        "for train, test in kfold.split(input_x, output_y):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=60, activation='relu'))\n",
        "\tmodel.add(Dense(60, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        "\tmodel.fit(input_x[train], output_y[train], epochs=150, batch_size=10, verbose=0)\n",
        " \n",
        "\tscores = model.evaluate(input_x[test], output_y[test], verbose=0)\n",
        " \n",
        "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\tcross_validationores_scores.append(scores[1] * 100)\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cross_validationores_scores), np.std(cross_validationores_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3173cc55ebcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'R'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irYoanqvWlFG"
      },
      "source": [
        "## Q4: Build a neural network by splitting the data using Keras\n",
        "\n",
        "- Use the dataset: data_02.csv\n",
        "- Split the columns into 34 input variables (input_x) and 1 output variable (output_y)\n",
        "- The output variable has string values; hence convert them into integer values 0 and 1.\n",
        "- You can select the number of hidden layers, activation functions, optimizer, batch size, and epochs of your choice.\n",
        "- Neural network paramaters: loss=binary_crossentropy, metrics=accuracy, validation_split=0.33.\n",
        "\n",
        "**Expected Output**\n",
        "- Validation accuracy: Greater than 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qBKaLJEAY-VF",
        "outputId": "b86ac465-470b-48eb-a205-19b3bf8cc079"
      },
      "source": [
        "# write your code here\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = read_csv(\"data_02.csv\", header=None)\n",
        "dataset = data.values\n",
        "\n",
        "input_x = dataset[:,0:34].astype(int)\n",
        "output_y = dataset[:,33].astype(int)\n",
        "\n",
        "encoding = LabelEncoder()\n",
        "encoding.fit(output_y)\n",
        "encoded_y = encoding.transform(output_y)\n",
        "\n",
        "# perform one hot encoding by converting convert integers to dummy variables\n",
        "dummy_output_y = np_utils.to_categorical(encoded_y)\n",
        "\n",
        "# define function baseline\n",
        "def baseline():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(8, input_dim=34, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        " \n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=baseline, epochs=200, batch_size=5, verbose=0)\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "prediction = cross_val_score(estimator, input_x, dummy_output_y, cv=kfold)\n",
        "\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (prediction.mean()*100, prediction.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 94.02% (2.96%)\n"
          ]
        }
      ]
    }
  ]
}