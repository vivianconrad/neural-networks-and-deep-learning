{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Save_DL_Model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"N3JqoFXDdMqI","executionInfo":{"status":"error","timestamp":1619755464539,"user_tz":300,"elapsed":456,"user":{"displayName":"Vmz Conrad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTeXio68o08aWvPGTs66yyv1pEkE-VYeMqXNJu9w=s64","userId":"07925550081713979769"}},"outputId":"dc9f773f-e1e4-4423-a9dd-0c0348a3ff2b"},"source":["# neural network with keras \n","from numpy import loadtxt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# load the dataset\n","data = loadtxt('cifar_indexes.txt', delimiter=',')\n","# split dataset into input variables and output variables\n","#input_x = data[:,0:8]\n","#output_y = data[:,8]\n","\n","# define the keras model\n","model = Sequential()\n","\n","# fully connected layers are defined using the Dense class\n","# we will use the relu activation function in the first two layers\n","\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","\n","\n","# sigmoid activation function is used in the output layer.\n","# It ensure our network output is between 0 and 1\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the keras model\n","# we use logarithmic loss, i.e., for binary classification problem in Keras is binary crossentropy.\n","# adam  is the efficient gradient decent algorithm used for optimization.\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","# fit the keras model on the dataset\n","# we can train or fit our model on our loaded data by calling the fit() function on the model.\n","# The training process will run for a fixed number of iterations through the dataset called epochs.\n","# The number of instances that are evaluated before a weight update in the network is performed called the batch size. \n","model.fit(input_x, output_y, epochs=100, batch_size=16)\n","\n","# evaluate the keras model\n","# we evaluate the model on the training dataset using the evaluation() function on\n","# the model and pass it the same input and output used to train the model.\n","_, accuracy = model.evaluate(input_x, output_y)\n","print('Accuracy: %.2f' % (accuracy*100))\n","model.save(\"model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c4229246afe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar-100-matlab.tar.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# split dataset into input variables and output variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#input_x = data[:,0:8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m                 \u001b[0mfirst_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m                 \u001b[0mfirst_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8c in position 1156: invalid start byte"]}]},{"cell_type":"code","metadata":{"id":"r8DOUkbxDddU"},"source":["# load and evaluate a saved model\n","from numpy import loadtxt\n","from keras.models import load_model\n"," \n","# load model\n","#model = load_model('model.h5')\n","tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n","\n","# summarize model.\n","model.summary()\n","\n","# load dataset\n","dataset = loadtxt(\"diabetes.csv\", delimiter=\",\")\n","\n","# split into input (X) and output (Y) variables\n","input_x = data[:,0:8]\n","output_y = data[:,8]\n","\n","# evaluate the model\n","score = model.evaluate(input_x, output_y, verbose=0)\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"],"execution_count":null,"outputs":[]}]}
