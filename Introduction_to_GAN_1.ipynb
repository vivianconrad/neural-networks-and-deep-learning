{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs_1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlI8fIcNZtGu"
      },
      "source": [
        "## Generative Adversarial Networks (GANs) - 1 Dimension Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVeLVXfsZtvW"
      },
      "source": [
        "# import packages\n",
        "from numpy import hstack\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDaUzbtQZEO9"
      },
      "source": [
        "# discriminator model \n",
        "\n",
        "def discriminator(n_inputs=2):\n",
        "\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\tmodel.add(Dense(50, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
        " \n",
        "  # kernel_initializer='he_uniform' - draws samples from a uniform distribution within [-limit, limit], \n",
        "  # where limit = sqrt(6 / fan_in) (fan_in is the number of input units in the weight tensor).\n",
        "\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\t# the model is complied\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_EnesltZIQ-"
      },
      "source": [
        "# generator model\n",
        "\n",
        "def generator(latent_dim, n_outputs=2):\n",
        "\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\tmodel.add(Dense(50, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
        "  \n",
        "  #kernel_initializer='he_uniform' - draws samples from a uniform distribution within [-limit, limit], \n",
        "  # where limit = sqrt(6 / fan_in) (fan_in is the number of input units in the weight tensor).\n",
        " \n",
        "\tmodel.add(Dense(n_outputs, activation='linear'))\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUyM3Z-BZN5c"
      },
      "source": [
        "# combine generator and discriminator models, update the generator\n",
        "\n",
        "def gan(generator_model, discriminator_model):\n",
        "\n",
        "\t# discriminator weights are not trainable\n",
        "\tdiscriminator.trainable = False\n",
        "\n",
        "\t# connect generator and discriminator\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\t# generator is added\n",
        "\tmodel.add(generator)\n",
        " \n",
        "\t# discriminator is added\n",
        "\tmodel.add(discriminator)\n",
        " \n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui9n6K9nZR8g"
      },
      "source": [
        "# data generation of n samples with class labels\n",
        "\n",
        "def real_samples(n):\n",
        "\n",
        "\t# data is generated between -0.5 to 0.5\n",
        "\tinput = rand(n) - 0.5\n",
        "\n",
        "\t# generate outputs X^2\n",
        "\toutput = input * input\n",
        "\n",
        "\t# stack arrays\n",
        "\tinput = input.reshape(n, 1)\n",
        "\toutput = output.reshape(n, 1)\n",
        " \n",
        "\tstack_arrays = hstack((input, output))\n",
        "  # numpy.hstack(tup) - stack arrays in sequence horizontally (column wise)\n",
        "  # This is equivalent to concatenation along the second axis, except for 1-D arrays \n",
        "  # where it concatenates along the first axis. Rebuilds arrays divided by hsplit.\n",
        " \n",
        "\t# class labels are generated\n",
        "\tclass_labels = ones((n, 1))\n",
        " \n",
        "\treturn stack_arrays, class_labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S2HnoyRZX3m"
      },
      "source": [
        "# latent space is generated and given as input for the generator\n",
        "\n",
        "def latent_space(latent_dim, n):\n",
        "\n",
        "\t# points in the latent space are generated\n",
        "\tpoints_latent = randn(latent_dim * n)\n",
        " \n",
        "\t# to feed it for the network, reshape into a batch of inputs\n",
        "\tpoints_latent = points_latent.reshape(n, latent_dim)\n",
        " \n",
        "\treturn points_latent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5nqGaHXZcEo"
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "\n",
        "def fake_samples(generator, latent_dim, n):\n",
        "\n",
        "\t# points are generated in the latent space\n",
        "\tfake_input = latent_space(latent_dim, n)\n",
        " \n",
        "\t# predict outputs\n",
        "\toutput = generator.predict(fake_input)\n",
        " \n",
        "\t# create class labels\n",
        "\tclass_labels = zeros((n, 1))\n",
        " \n",
        "\treturn output, class_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmCh2n1jZfKN"
      },
      "source": [
        "# discriminator is evaluated and the results of real vs fake points are plotted\n",
        "\n",
        "def performance(epoch, generator, discriminator, latent_dim, n=100):\n",
        "\n",
        "\t# original samples are generated\n",
        "\toriginal_data, original_label = real_samples(n)\n",
        " \n",
        "\t# discriminator performance on original samples are evaluated\n",
        "\toriginal_loss, original_accuracy = discriminator.evaluate(original_data, original_label, verbose=0)\n",
        " \n",
        "\t# fake samples are generated\n",
        "\tfake_data, fake_label = fake_samples(generator, latent_dim, n)\n",
        " \n",
        "\t# discriminator performance on fake samples are evaluated\n",
        "\tfake_loss, fake_accuracy = discriminator.evaluate(fake_data, fake_label, verbose=0)\n",
        " \n",
        "\t# for every epoch, original accuracy and fake accuracy of discriminator is printed\n",
        "\tprint(epoch, original_accuracy, fake_accuracy)\n",
        " \n",
        "\t# plot the original and fake points\n",
        "\tpyplot.scatter(original_data[:, 0], original_data[:, 1], color='red')\n",
        "\tpyplot.scatter(fake_data[:, 0], fake_data[:, 1], color='blue')\n",
        " \n",
        "\t# every 2000 epochs, the plots are saved to files\n",
        "\tfile_name = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(file_name)\n",
        "\tpyplot.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4NcdvXJZiSG"
      },
      "source": [
        "# train the generator and discriminator\n",
        "\n",
        "def train_generator_discriminator(generator_model, discriminator_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
        "\n",
        "\t# to update the discriminator, calculate half the size of one batch\n",
        "\tbatch_half = int(n_batch / 2)\n",
        " \n",
        "\t# enumerate epochs manually \n",
        "\tfor i in range(n_epochs):\n",
        "   \n",
        "\t\t# original samples are prepared\n",
        "\t\toriginal_data, original_label = real_samples(batch_half)\n",
        "  \n",
        "\t\t# fake samples are prepared\n",
        "\t\tfake_data, fake_label = fake_samples(generator_model, latent_dim, batch_half)\n",
        "  \n",
        "\t\t# the discriminator is updated\n",
        "\t\tdiscriminator_model.train_on_batch(original_data, original_label)\n",
        "\t\tdiscriminator_model.train_on_batch(fake_data, fake_label)\n",
        "  \n",
        "\t\t# as input for the generator prepare points in the latent space\n",
        "\t\tx_gan = latent_space(latent_dim, n_batch)\n",
        "  \n",
        "\t\t# for the fake samples create inverted labels \n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "  \n",
        "\t\t# using the discriminator's error update the generator\n",
        "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
        "  \n",
        "\t\t# print the models performance every 2000 epochs\n",
        "\t\tif (i+1) % n_eval == 0:\n",
        "\t\t\tperformance(i, generator_model, discriminator_model, latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zi7c7vHZomY",
        "outputId": "f1386954-b2d4-440a-ae00-b74d441dcffd"
      },
      "source": [
        "# latent space size is set to 5\n",
        "latent_dim = 5\n",
        "\n",
        "# call the discriminator function\n",
        "discriminator = discriminator()\n",
        "\n",
        "# call the generator function\n",
        "generator = generator(latent_dim)\n",
        "\n",
        "# call the gan function\n",
        "gan_model = gan(generator, discriminator)\n",
        "\n",
        "# train the generator and discriminator model\n",
        "train_generator_discriminator(generator, discriminator, gan_model, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999 0.6399999856948853 1.0\n",
            "3999 0.5899999737739563 0.5400000214576721\n",
            "5999 0.6399999856948853 0.5400000214576721\n",
            "7999 0.7400000095367432 0.5600000023841858\n",
            "9999 0.5400000214576721 0.44999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df1gK_Mj9tG-"
      },
      "source": [
        "Acknowledgement: Jason Brownlee, Generative Adversarial Networks with Python, Machine Learning Mastery, Available from https://machinelearningmastery.com/generative_adversarial_networks/, accessed  March 15th, 2021."
      ]
    }
  ]
}
