{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_Learning_01.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ocSD9fZPdL7m"},"source":["## First Neural Network With Keras\n","- Diabetes dataset from available for free download from the UCI Machine Learning repository.\n","- Binary classification proble"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3JqoFXDdMqI","executionInfo":{"status":"ok","timestamp":1615230116359,"user_tz":360,"elapsed":9162,"user":{"displayName":"Vmz Conrad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTeXio68o08aWvPGTs66yyv1pEkE-VYeMqXNJu9w=s64","userId":"07925550081713979769"}},"outputId":"5fdbb461-1c49-4992-b3d3-f6f87736a79a"},"source":["# neural network with keras \n","from numpy import loadtxt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# load the dataset\n","data = loadtxt('diabetes-1.csv', delimiter=',')\n","# split dataset into input variables and output variables\n","input_x = data[:,0:8]\n","output_y = data[:,8]\n","\n","# define the keras model\n","model = Sequential()\n","\n","# fully connected layers are defined using the Dense class\n","# we will use the relu activation function in the first two layers\n","\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","\n","\n","# sigmoid activation function is used in the output layer.\n","# It ensure our network output is between 0 and 1\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the keras model\n","# we use logarithmic loss, i.e., for binary classification problem in Keras is binary crossentropy.\n","# adam  is the efficient gradient decent algorithm used for optimization.\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","# fit the keras model on the dataset\n","# we can train or fit our model on our loaded data by calling the fit() function on the model.\n","# The training process will run for a fixed number of iterations through the dataset called epochs.\n","# The number of instances that are evaluated before a weight update in the network is performed called the batch size. \n","model.fit(input_x, output_y, epochs=100, batch_size=16)\n","\n","# evaluate the keras model\n","# we evaluate the model on the training dataset using the evaluation() function on\n","# the model and pass it the same input and output used to train the model.\n","_, accuracy = model.evaluate(input_x, output_y)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","48/48 [==============================] - 1s 1ms/step - loss: 11.4167 - accuracy: 0.3279\n","Epoch 2/100\n","48/48 [==============================] - 0s 1ms/step - loss: 4.3704 - accuracy: 0.3799\n","Epoch 3/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 0.5216\n","Epoch 4/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6292\n","Epoch 5/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6534\n","Epoch 6/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6485\n","Epoch 7/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6358\n","Epoch 8/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6292\n","Epoch 9/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6217\n","Epoch 10/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6639\n","Epoch 11/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6594\n","Epoch 12/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6552\n","Epoch 13/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.6656\n","Epoch 14/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.6507\n","Epoch 15/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5972 - accuracy: 0.6745\n","Epoch 16/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6735\n","Epoch 17/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.6843\n","Epoch 18/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6955\n","Epoch 19/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6470\n","Epoch 20/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6843\n","Epoch 21/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6450\n","Epoch 22/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6719\n","Epoch 23/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6538\n","Epoch 24/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6749\n","Epoch 25/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6800\n","Epoch 26/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6888\n","Epoch 27/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5990 - accuracy: 0.6477\n","Epoch 28/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6592\n","Epoch 29/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.6755\n","Epoch 30/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6799\n","Epoch 31/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6940\n","Epoch 32/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6692\n","Epoch 33/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6672\n","Epoch 34/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.6630\n","Epoch 35/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6396\n","Epoch 36/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.6921\n","Epoch 37/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.6817\n","Epoch 38/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6701\n","Epoch 39/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6344\n","Epoch 40/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6990\n","Epoch 41/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.6836\n","Epoch 42/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5919 - accuracy: 0.6688\n","Epoch 43/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.6694\n","Epoch 44/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6595\n","Epoch 45/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.6807\n","Epoch 46/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6722\n","Epoch 47/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6486\n","Epoch 48/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6822\n","Epoch 49/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5850 - accuracy: 0.6632\n","Epoch 50/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.6886\n","Epoch 51/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.6587\n","Epoch 52/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6807\n","Epoch 53/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6679\n","Epoch 54/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.6827\n","Epoch 55/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6761\n","Epoch 56/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6887\n","Epoch 57/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6596\n","Epoch 58/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6557\n","Epoch 59/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6676\n","Epoch 60/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.6817\n","Epoch 61/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.6604\n","Epoch 62/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6588\n","Epoch 63/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6732\n","Epoch 64/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.6576\n","Epoch 65/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6739\n","Epoch 66/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.6966\n","Epoch 67/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6785\n","Epoch 68/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.6931\n","Epoch 69/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.6824\n","Epoch 70/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6586\n","Epoch 71/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.6873\n","Epoch 72/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.6769\n","Epoch 73/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.6917\n","Epoch 74/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.6921\n","Epoch 75/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.6807\n","Epoch 76/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6558\n","Epoch 77/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.6606\n","Epoch 78/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7062\n","Epoch 79/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6437\n","Epoch 80/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6476\n","Epoch 81/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7003\n","Epoch 82/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6659\n","Epoch 83/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6754\n","Epoch 84/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6619\n","Epoch 85/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.6909\n","Epoch 86/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6720\n","Epoch 87/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6712\n","Epoch 88/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6702\n","Epoch 89/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6540\n","Epoch 90/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6687\n","Epoch 91/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.6563\n","Epoch 92/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5834 - accuracy: 0.6671\n","Epoch 93/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.6885\n","Epoch 94/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6767\n","Epoch 95/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6657\n","Epoch 96/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.6829\n","Epoch 97/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.6855\n","Epoch 98/100\n","48/48 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6601\n","Epoch 99/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6648\n","Epoch 100/100\n","48/48 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6897\n","24/24 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.6784\n","Accuracy: 67.84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXEy8doGZTxz","outputId":"f09ba804-9121-4a4b-a2b1-3ed55d5ab37f"},"source":["# neural network with keras \n","from numpy import loadtxt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy as np\n","\n","# load the dataset\n","data = loadtxt('diabetes.csv', delimiter=',')\n","# split dataset into input variables and output variables\n","input_x = data[:,0:8]\n","output_y = data[:,8]\n","\n","# define the keras model\n","model = Sequential()\n","\n","# fully connected layers are defined using the Dense class\n","# we will use the relu activation function in the first two layers\n","\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","\n","\n","# sigmoid activation function is used in the output layer.\n","# It ensure our network output is between 0 and 1\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the keras model\n","# we use logarithmic loss, i.e., for binary classification problem in Keras is binary crossentropy.\n","# adam  is the efficient gradient decent algorithm used for optimization.\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# fit the keras model on the dataset\n","model.fit(input_x, output_y, epochs=150, batch_size=10, verbose=0)\n","#verbose=0 will show you nothing (silent)\n","#verbose=1 will show you an animated progress bar like this:\n","\n","# make class predictions with the model\n","predictions = model.predict_classes(input_x)\n","\n","\n","# summarize the first 10 cases\n","for i in range(10):\n","\tprint('%s => %d (expected %d)' % (input_x[i].tolist(), predictions[i], output_y[i]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n","[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n","[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n","[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n","[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n","[5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0] => 0 (expected 0)\n","[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.248, 26.0] => 0 (expected 1)\n","[10.0, 115.0, 0.0, 0.0, 0.0, 35.3, 0.134, 29.0] => 0 (expected 0)\n","[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.158, 53.0] => 1 (expected 1)\n","[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.232, 54.0] => 1 (expected 1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRDRPZ6mj5cE","outputId":"23f25984-12be-4938-b78d-bc145b12c357"},"source":["arr = np.array([[9,1,6],\n","                [24,28,20],\n","                [27,7,59]])\n","print('When axis = None')\n","print(np.argmax(arr))\n","print('\\nWhen axis = 0')\n","print(np.argmax(arr,axis=0))\n","print('\\nWhen axis = 1')\n","print(np.argmax(arr, axis=-1))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["When axis = None\n","8\n","\n","When axis = 0\n","[2 1 2]\n","\n","When axis = 1\n","[0 1 2]\n"],"name":"stdout"}]}]}